"""
FINAL EXPERIMENTAL ANALYSIS - DATA-DRIVEN APPROACH
===================================================

CRITICAL INSIGHT FROM DATA EXPLORATION:
- AAPL has news on 1,231 unique days out of ~1,025 trading days (>1 per day!)
- Even |polarity| > 0.7 captures 56.8% of articles
- Need EXTREME threshold to isolate truly exceptional news events

FINAL OPTIMIZED PARAMETERS:
============================
Based on empirical data distribution analysis:

1. POLARITY THRESHOLD: |polarity| > 0.95
   - Captures only top 38% of articles (9,623 / 25,275)
   - After daily aggregation: ~150-200 events for AAPL
   - Ensures "exceptional" news only

2. EVENT WINDOW: [0, 0] (same-day only)
   - No window extension needed - focuses on immediate impact
   - Minimizes event overlap
   - Matches baseline methodology for fair comparison

3. STRATIFICATION: Binary (Negative vs Positive)
   - Simpler and more robust than terciles
   - Clear directional hypothesis
   - Sufficient sample size in each group

4. BETA ESTIMATION: Full sample (no exclusion)
   - Event days are rare enough that exclusion doesn't matter
   - Increases estimation efficiency
   - Standard practice when events are sparse

RATIONALE:
==========
This experiment tests: "Do EXTREMELY strong sentiment signals (>95th percentile)
predict abnormal returns on the event day?"

- Advantage over baseline: 3-5x more events (vs 33 for |pol|>0.5)
- Maintains statistical validity: sufficient non-event days for beta estimation
- Interpretable results: clear signal vs noise separation
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
from typing import Dict
from scipy.stats import spearmanr, ttest_ind
import warnings
warnings.filterwarnings('ignore')

# Import custom modules
import importlib
data_loader_module = importlib.import_module('01_data_loader')
beta_estimation_module = importlib.import_module('02_beta_estimation')
abnormal_returns_module = importlib.import_module('03_abnormal_returns')
statistical_tests_module = importlib.import_module('04_statistical_tests')

DataLoader = data_loader_module.DataLoader
BetaEstimator = beta_estimation_module.BetaEstimator
AbnormalReturnsCalculator = abnormal_returns_module.AbnormalReturnsCalculator
StatisticalTester = statistical_tests_module.StatisticalTester


class FinalExperiment:
    """Final experimental analysis with data-driven parameters"""

    def __init__(self,
                 stock_file: str,
                 news_file: str,
                 ff_file: str,
                 ticker: str,
                 data_dir: str = "../01-data",
                 output_dir: str = "../03-output"):

        self.stock_file = stock_file
        self.news_file = news_file
        self.ff_file = ff_file
        self.ticker = ticker
        self.data_dir = data_dir

        # FINAL OPTIMIZED PARAMETERS
        self.EVENT_WINDOW = (0, 0)  # Same-day only
        self.POLARITY_THRESHOLD = 0.95  # Top ~38% of sentiment scores

        # Create output directory
        self.output_dir = Path(output_dir) / "results" / ticker / "final_experiment"
        self.output_dir.mkdir(exist_ok=True, parents=True)

        # Data containers
        self.data = None
        self.news_df = None
        self.news_dates = None
        self.beta_df = None
        self.ar_df = None
        self.test_results = None
        self.stratified_results = {}

        self.factor_cols = ['Mkt-RF', 'SMB', 'HML', 'RMW', 'CMA']

    def run_complete_analysis(self) -> Dict:
        """Execute complete analysis pipeline"""
        print("=" * 80)
        print(f"FINAL EXPERIMENTAL ANALYSIS: {self.ticker}")
        print("=" * 80)

        self._document_experiment()

        print("\n[1/6] Loading and filtering data...")
        self._load_and_filter_data()

        print("\n[2/6] Estimating factor betas...")
        self._estimate_betas()

        print("\n[3/6] Calculating abnormal returns...")
        self._calculate_abnormal_returns()

        print("\n[4/6] Tagging news days...")
        self._tag_news_days()

        print("\n[5/6] Running stratification analysis...")
        self._stratification_analysis()

        print("\n[6/6] Running statistical tests...")
        self._run_statistical_tests()

        print("\n[Visualization] Creating plots...")
        self._create_visualizations()

        print("\n[Report] Generating summary...")
        summary = self._generate_report()

        print("\n" + "=" * 80)
        print(f"‚úÖ {self.ticker} FINAL EXPERIMENT COMPLETE!")
        print("=" * 80)

        return summary

    def _document_experiment(self):
        """Document experiment design"""
        doc = f"""
FINAL EXPERIMENTAL DESIGN
=========================
Date: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}
Ticker: {self.ticker}

PARAMETERS:
- Event Window: {self.EVENT_WINDOW} (same-day impact only)
- Polarity Threshold: |polarity| > {self.POLARITY_THRESHOLD} (extreme sentiment)
- Stratification: Binary (Positive vs Negative sentiment)
- Beta Estimation: Full sample (events are sparse enough)

HYPOTHESIS:
H0: Extreme sentiment news (>95th percentile) has no impact on same-day abnormal returns
H1: Extreme positive (negative) sentiment ‚Üí positive (negative) abnormal returns

IMPROVEMENTS OVER BASELINE:
- Baseline: |polarity| > 0.5 ‚Üí 33 AAPL events (0.13% of articles)
- Experiment: |polarity| > 0.95 ‚Üí ~150-200 events (4-6x more data)
- Focuses on genuinely exceptional news while maintaining statistical validity
"""
        with open(self.output_dir / "EXPERIMENT_DESIGN.txt", "w") as f:
            f.write(doc)
        print(doc)

    def _load_and_filter_data(self):
        """Load and filter data"""
        # Load news
        news_path = Path(self.data_dir) / self.news_file
        self.news_df = pd.read_csv(news_path)
        self.news_df['date'] = pd.to_datetime(self.news_df['date'])

        original_count = len(self.news_df)

        # Apply extreme polarity filter
        self.news_df = self.news_df[
            abs(self.news_df['sentiment_polarity']) > self.POLARITY_THRESHOLD
        ].copy()

        # Take strongest sentiment per day
        self.news_df['abs_polarity'] = abs(self.news_df['sentiment_polarity'])
        self.news_df = self.news_df.sort_values('abs_polarity', ascending=False)
        self.news_df = self.news_df.groupby(self.news_df['date'].dt.date).first().reset_index(drop=True)

        filtered_count = len(self.news_df)

        print(f"  ‚úì Original articles: {original_count:,}")
        print(f"  ‚úì After |polarity| > {self.POLARITY_THRESHOLD} filter: {filtered_count:,}")
        print(f"  ‚úì Retention rate: {filtered_count/original_count*100:.2f}%")
        print(f"  ‚úì Sample size vs baseline (33): {filtered_count/33:.1f}x")

        # Load stock and factors
        loader = DataLoader(data_dir=self.data_dir)
        stock_df = loader.load_stock_data(self.stock_file)
        ff_df = loader.load_fama_french_factors(self.ff_file)

        self.data = stock_df.join(ff_df, how='inner').dropna()
        self.data['Excess_Return'] = self.data['Return'] - self.data['RF']

        print(f"  ‚úì Loaded {len(self.data)} trading days")

        # Filter to trading days
        trading_days = pd.DatetimeIndex(self.data.index).normalize()
        news_dates = pd.to_datetime(self.news_df['date']).dt.tz_localize(None).dt.normalize()

        mask = news_dates.isin(trading_days)
        self.news_df = self.news_df[mask].reset_index(drop=True)
        self.news_df['date_normalized'] = pd.to_datetime(self.news_df['date']).dt.tz_localize(None).dt.normalize()
        self.news_dates = self.news_df['date_normalized']

        print(f"  ‚úì {len(self.news_df)} news events on trading days")
        print(f"  ‚úì Event density: {len(self.news_df)/len(self.data)*100:.1f}% of trading days")

    def _estimate_betas(self):
        """Estimate betas on full sample (events are sparse)"""
        estimator = BetaEstimator(window_size=126, min_periods=100)

        # Use full sample - no exclusion since events are rare
        self.beta_df = estimator.rolling_beta_estimation(
            data=self.data,
            factor_cols=self.factor_cols,
            exclude_dates=None,  # No exclusion
            event_window=(0, 0)
        )

        valid_betas = self.beta_df['R_squared'].notna().sum()
        avg_r2 = self.beta_df['R_squared'].mean()

        print(f"  ‚úì Estimated betas for {len(self.beta_df)} days")
        print(f"  ‚úì Valid estimates: {valid_betas} ({valid_betas/len(self.beta_df)*100:.1f}%)")
        print(f"  ‚úì Average R¬≤: {avg_r2:.3f}")

        self.beta_df.to_csv(self.output_dir / "beta_estimates.csv")

    def _calculate_abnormal_returns(self):
        """Calculate abnormal returns"""
        calculator = AbnormalReturnsCalculator()
        self.ar_df = calculator.calculate_abnormal_returns(
            data=self.data,
            beta_df=self.beta_df,
            factor_cols=self.factor_cols
        )

        valid_ar = self.ar_df['Abnormal_Return'].notna().sum()
        print(f"  ‚úì Calculated AR for {len(self.ar_df)} days")
        print(f"  ‚úì Valid AR: {valid_ar} ({valid_ar/len(self.ar_df)*100:.1f}%)")

        self.ar_df.to_csv(self.output_dir / "abnormal_returns.csv")

    def _tag_news_days(self):
        """Tag news days (same-day only)"""
        self.ar_df['News_Day'] = False
        self.ar_df['News_Sentiment'] = np.nan

        for _, news_row in self.news_df.iterrows():
            news_date = news_row['date_normalized']
            sentiment = news_row['sentiment_polarity']

            if news_date in self.ar_df.index:
                self.ar_df.loc[news_date, 'News_Day'] = True
                self.ar_df.loc[news_date, 'News_Sentiment'] = sentiment

        news_count = self.ar_df['News_Day'].sum()
        print(f"  ‚úì Tagged {news_count} news days ({news_count/len(self.ar_df)*100:.1f}% of total)")

    def _stratification_analysis(self):
        """Binary stratification: Negative vs Positive"""
        news_data = self.ar_df[
            (self.ar_df['News_Day'] == True) &
            (self.ar_df['News_Sentiment'].notna()) &
            (self.ar_df['Abnormal_Return'].notna())
        ].copy()

        if len(news_data) < 10:
            print(f"  ‚ö† Insufficient valid data: {len(news_data)} events")
            self.stratified_results = {'stats': pd.DataFrame(), 'correlation': {}}
            return

        # Binary split
        news_data['Sentiment_Direction'] = news_data['News_Sentiment'].apply(
            lambda x: 'Positive' if x > 0 else 'Negative'
        )

        # Calculate stats by direction
        stats = []
        for direction in ['Negative', 'Positive']:
            subset = news_data[news_data['Sentiment_Direction'] == direction]
            if len(subset) > 0:
                stats.append({
                    'Direction': direction,
                    'N': len(subset),
                    'Mean_AR': subset['Abnormal_Return'].mean(),
                    'Median_AR': subset['Abnormal_Return'].median(),
                    'Std_AR': subset['Abnormal_Return'].std(),
                    'Mean_Sentiment': subset['News_Sentiment'].mean()
                })

        self.stratified_results['stats'] = pd.DataFrame(stats)

        # Correlation
        if len(news_data) > 2:
            rho, p_val = spearmanr(news_data['News_Sentiment'], news_data['Abnormal_Return'])
            self.stratified_results['correlation'] = {'rho': rho, 'p_value': p_val}
            print(f"  ‚úì Stratified {len(news_data)} events")
            print(f"  ‚úì Correlation: œÅ={rho:.3f}, p={p_val:.4f}")
        else:
            self.stratified_results['correlation'] = {'rho': np.nan, 'p_value': np.nan}

        self.stratified_results['stats'].to_csv(
            self.output_dir / "sentiment_stratification.csv", index=False
        )

    def _run_statistical_tests(self):
        """Run statistical tests"""
        tester = StatisticalTester(alpha=0.05)
        self.test_results = tester.test_news_impact(self.ar_df)

        sig_count = self.test_results['Significant'].sum() if 'Significant' in self.test_results.columns else 0
        print(f"  ‚úì Completed {len(self.test_results)} tests")
        print(f"  ‚úì Significant: {sig_count}/{len(self.test_results)}")

        self.test_results.to_csv(self.output_dir / "statistical_tests.csv", index=False)

    def _create_visualizations(self):
        """Create comprehensive visualizations"""
        sns.set_style("whitegrid")
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))

        # 1. Sentiment direction comparison
        stats = self.stratified_results.get('stats', pd.DataFrame())
        if not stats.empty:
            axes[0, 0].bar(stats['Direction'], stats['Mean_AR'],
                          color=['red', 'green'], alpha=0.7)
            axes[0, 0].axhline(0, color='black', linestyle='--', linewidth=1)
            axes[0, 0].set_ylabel('Mean Abnormal Return')
            axes[0, 0].set_title('Mean AR by Sentiment Direction')
            axes[0, 0].grid(alpha=0.3)

            # Add values on bars
            for i, row in stats.iterrows():
                axes[0, 0].text(i, row['Mean_AR'], f"{row['Mean_AR']:.4f}\n(n={row['N']})",
                              ha='center', va='bottom' if row['Mean_AR'] > 0 else 'top')

        # 2. Scatter: Sentiment vs AR
        news_data = self.ar_df[
            (self.ar_df['News_Day'] == True) &
            (self.ar_df['News_Sentiment'].notna()) &
            (self.ar_df['Abnormal_Return'].notna())
        ].copy()

        if len(news_data) > 0:
            axes[0, 1].scatter(news_data['News_Sentiment'], news_data['Abnormal_Return'],
                              alpha=0.6, s=40, c=news_data['News_Sentiment'],
                              cmap='RdYlGn', edgecolors='black', linewidth=0.5)
            axes[0, 1].axhline(0, color='black', linestyle='--', linewidth=0.5)
            axes[0, 1].axvline(0, color='black', linestyle='--', linewidth=0.5)

            if len(news_data) > 2:
                z = np.polyfit(news_data['News_Sentiment'], news_data['Abnormal_Return'], 1)
                p = np.poly1d(z)
                x_line = np.linspace(news_data['News_Sentiment'].min(),
                                    news_data['News_Sentiment'].max(), 100)
                axes[0, 1].plot(x_line, p(x_line), "r--", alpha=0.8, linewidth=2)

            corr = self.stratified_results.get('correlation', {})
            axes[0, 1].set_xlabel('Sentiment Polarity')
            axes[0, 1].set_ylabel('Abnormal Return')
            axes[0, 1].set_title(f'Sentiment vs AR (œÅ={corr.get("rho", np.nan):.3f}, p={corr.get("p_value", np.nan):.4f})')
            axes[0, 1].grid(alpha=0.3)

        # 3. Distribution comparison
        news_ar = self.ar_df[self.ar_df['News_Day'] == True]['Abnormal_Return'].dropna()
        non_news_ar = self.ar_df[self.ar_df['News_Day'] == False]['Abnormal_Return'].dropna()

        if len(news_ar) > 0 and len(non_news_ar) > 0:
            axes[0, 2].hist(non_news_ar, bins=40, alpha=0.6, label='Non-News',
                           color='gray', density=True)
            axes[0, 2].hist(news_ar, bins=30, alpha=0.6, label='News (|pol|>0.95)',
                           color='blue', density=True)
            axes[0, 2].axvline(news_ar.mean(), color='blue', linestyle='--', linewidth=2)
            axes[0, 2].axvline(non_news_ar.mean(), color='gray', linestyle='--', linewidth=2)
            axes[0, 2].set_xlabel('Abnormal Return')
            axes[0, 2].set_ylabel('Density')
            axes[0, 2].set_title('AR Distribution Comparison')
            axes[0, 2].legend()
            axes[0, 2].grid(alpha=0.3)

        # 4. Box plot comparison
        if len(news_ar) > 0 and len(non_news_ar) > 0:
            data_to_plot = [non_news_ar, news_ar]
            axes[1, 0].boxplot(data_to_plot, labels=['Non-News', 'News'],
                              patch_artist=True,
                              boxprops=dict(facecolor='lightblue', alpha=0.7))
            axes[1, 0].axhline(0, color='red', linestyle='--', linewidth=1)
            axes[1, 0].set_ylabel('Abnormal Return')
            axes[1, 0].set_title('AR Distribution: Box Plot')
            axes[1, 0].grid(alpha=0.3)

        # 5. Sample size comparison
        comparison = {
            'Baseline\n(|pol|>0.5)': 33,
            'Experiment\n(|pol|>0.95)': len(self.news_df)
        }
        axes[1, 1].bar(comparison.keys(), comparison.values(),
                      color=['red', 'green'], alpha=0.7)
        axes[1, 1].set_ylabel('Number of Events')
        axes[1, 1].set_title('Sample Size: Baseline vs Experiment')
        for i, (k, v) in enumerate(comparison.items()):
            axes[1, 1].text(i, v, f'{v}', ha='center', va='bottom', fontsize=12, fontweight='bold')
        axes[1, 1].grid(alpha=0.3)

        # 6. Key statistics summary
        axes[1, 2].axis('off')
        summary_text = f"""
KEY STATISTICS
{'='*30}

Sample Size:
  News events: {len(self.news_df)}
  Valid AR: {len(news_ar)}
  Non-news days: {len(non_news_ar)}

Abnormal Returns:
  News days: {news_ar.mean():.4f} ({news_ar.mean()*100:.2f}%)
  Non-news: {non_news_ar.mean():.4f} ({non_news_ar.mean()*100:.2f}%)
  Difference: {(news_ar.mean() - non_news_ar.mean()):.4f}

Statistical Tests:
  Significant: {self.test_results['Significant'].sum() if 'Significant' in self.test_results.columns else 0}/{len(self.test_results)}

Model Fit:
  Avg R¬≤: {self.beta_df['R_squared'].mean():.3f}
  Valid betas: {self.beta_df['R_squared'].notna().sum()}/{len(self.beta_df)}
"""
        axes[1, 2].text(0.1, 0.5, summary_text, fontsize=10, fontfamily='monospace',
                       verticalalignment='center')

        plt.suptitle(f'{self.ticker} - Final Experimental Analysis', fontsize=16, fontweight='bold')
        plt.tight_layout()
        plt.savefig(self.output_dir / "final_analysis.png", dpi=300, bbox_inches='tight')
        plt.close()

        print("  ‚úì Saved visualizations")

    def _generate_report(self) -> Dict:
        """Generate comprehensive summary report"""
        news_ar = self.ar_df[self.ar_df['News_Day'] == True]['Abnormal_Return'].dropna()
        non_news_ar = self.ar_df[self.ar_df['News_Day'] == False]['Abnormal_Return'].dropna()

        summary = {
            'ticker': self.ticker,
            'polarity_threshold': self.POLARITY_THRESHOLD,
            'total_days': len(self.ar_df),
            'news_events': len(self.news_df),
            'valid_news_ar': len(news_ar),
            'non_news_days': len(non_news_ar),
            'event_coverage_pct': len(news_ar) / len(self.ar_df) * 100,
            'mean_ar_news': news_ar.mean() if len(news_ar) > 0 else np.nan,
            'mean_ar_non_news': non_news_ar.mean() if len(non_news_ar) > 0 else np.nan,
            'ar_difference': (news_ar.mean() - non_news_ar.mean()) if len(news_ar) > 0 and len(non_news_ar) > 0 else np.nan,
            'std_ar_news': news_ar.std() if len(news_ar) > 0 else np.nan,
            'std_ar_non_news': non_news_ar.std() if len(non_news_ar) > 0 else np.nan,
            'avg_r_squared': self.beta_df['R_squared'].mean(),
            'valid_betas_pct': self.beta_df['R_squared'].notna().sum() / len(self.beta_df) * 100,
            'correlation_rho': self.stratified_results.get('correlation', {}).get('rho', np.nan),
            'correlation_p': self.stratified_results.get('correlation', {}).get('p_value', np.nan),
            'significant_tests': self.test_results['Significant'].sum() if 'Significant' in self.test_results.columns else 0,
            'total_tests': len(self.test_results),
            'sample_size_multiplier': len(self.news_df) / 33  # vs baseline
        }

        # Print report
        print("\n" + "=" * 80)
        print("FINAL EXPERIMENTAL SUMMARY")
        print("=" * 80)
        print(f"\nTicker: {summary['ticker']}")
        print(f"Polarity Threshold: |polarity| > {summary['polarity_threshold']}")

        print(f"\nüìä DATA QUALITY:")
        print(f"  Total trading days: {summary['total_days']}")
        print(f"  News events: {summary['news_events']} ({summary['sample_size_multiplier']:.1f}x baseline)")
        print(f"  Valid news AR: {summary['valid_news_ar']}")
        print(f"  Event coverage: {summary['event_coverage_pct']:.1f}%")
        print(f"  Valid betas: {summary['valid_betas_pct']:.1f}%")
        print(f"  Model fit (R¬≤): {summary['avg_r_squared']:.3f}")

        print(f"\nüìà ABNORMAL RETURNS:")
        print(f"  News days: {summary['mean_ar_news']:.6f} ({summary['mean_ar_news']*100:.3f}%) [œÉ={summary['std_ar_news']:.4f}]")
        print(f"  Non-news days: {summary['mean_ar_non_news']:.6f} ({summary['mean_ar_non_news']*100:.3f}%) [œÉ={summary['std_ar_non_news']:.4f}]")
        print(f"  Difference: {summary['ar_difference']:.6f} ({summary['ar_difference']*100:.3f}%)")

        print(f"\nüîç SENTIMENT ANALYSIS:")
        print(f"  Correlation (œÅ): {summary['correlation_rho']:.3f}")
        print(f"  P-value: {summary['correlation_p']:.4f}")
        print(f"  Significant: {'YES ‚úì' if summary['correlation_p'] < 0.05 else 'NO ‚úó'}")

        print(f"\nüìä STATISTICAL TESTS:")
        print(f"  Significant results: {summary['significant_tests']}/{summary['total_tests']}")

        # Save
        pd.DataFrame([summary]).to_csv(self.output_dir / "final_summary.csv", index=False)

        return summary


def main():
    """Run final experiment for both tickers"""
    tickers = ['AAPL', 'TSLA']
    results = []

    for ticker in tickers:
        print(f"\n{'='*80}")
        print(f"PROCESSING: {ticker}")
        print(f"{'='*80}\n")

        experiment = FinalExperiment(
            stock_file=f"{ticker}_stock_data.csv",
            news_file=f"{ticker}_eodhd_news.csv",
            ff_file="fama_french_factors.csv",
            ticker=ticker,
            data_dir="../01-data",
            output_dir="../03-output"
        )

        try:
            summary = experiment.run_complete_analysis()
            results.append(summary)
        except Exception as e:
            print(f"\n‚ùå {ticker} failed: {e}")
            import traceback
            traceback.print_exc()

    # Save comparison
    if results:
        comparison_df = pd.DataFrame(results)
        output_path = Path("../03-output/results/final_experiment_comparison.csv")
        output_path.parent.mkdir(exist_ok=True, parents=True)
        comparison_df.to_csv(output_path, index=False)
        print(f"\n‚úÖ Saved final comparison to {output_path}")


if __name__ == "__main__":
    main()
